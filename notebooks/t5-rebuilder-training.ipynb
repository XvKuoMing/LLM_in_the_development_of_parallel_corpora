{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n! pip install transformers\n! pip install accelerate -U\n! pip install datasets\n\n! pip install evaluate\n! pip install sacrebleu","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:24:15.883599Z","iopub.execute_input":"2024-05-15T09:24:15.884024Z","iopub.status.idle":"2024-05-15T09:25:18.746273Z","shell.execute_reply.started":"2024-05-15T09:24:15.884000Z","shell.execute_reply":"2024-05-15T09:25:18.744988Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"XvKuoMing/casings\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:25:18.749461Z","iopub.execute_input":"2024-05-15T09:25:18.750238Z","iopub.status.idle":"2024-05-15T09:25:21.677192Z","shell.execute_reply.started":"2024-05-15T09:25:18.750201Z","shell.execute_reply":"2024-05-15T09:25:21.676317Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"ai-forever/ruT5-base\"\n# checkpoint = \"sn4kebyt3/ru-bart-large\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint,\n                                          add_prefix_space=True,\n                                          device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:25:21.678425Z","iopub.execute_input":"2024-05-15T09:25:21.678732Z","iopub.status.idle":"2024-05-15T09:25:28.964200Z","shell.execute_reply.started":"2024-05-15T09:25:21.678707Z","shell.execute_reply":"2024-05-15T09:25:28.963136Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1e04abed85e45edbc6c7fd614673f6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dae7801adb654c29bc90063df594e7a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ebc1072b4de4e14b88212d9b0f66318"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\n\nMAX_LENGTH = 24\n\ndef preprocess(batch):\n\n    targs = {'max_length':MAX_LENGTH,\n             'truncation':True,\n             'is_split_into_words':True}\n    lemmas = []\n    tokens = []\n    for n, sub_lemmas in enumerate(batch['lemmas']):\n        if len(sub_lemmas) > MAX_LENGTH or not bool(sub_lemmas):\n            continue\n        sub_tokens = batch['tokens'][n]\n        while sub_lemmas[-1] == '.':\n            sub_lemmas = sub_lemmas[:-1]\n            sub_tokens = sub_tokens[:-1]\n#         lemmas.append(sub_lemmas)\n#         tokens.append(sub_tokens)\n        # corrupting \n        last = 0\n        step = 4\n        corrupted = []\n        for _ in range(len(sub_lemmas[::step])):\n            sent_piece = sub_lemmas[last:last+step]\n            corrupted.append(\n                sub_lemmas[:last] + random.sample(sent_piece, len(sent_piece)) + sub_lemmas[last+step:]\n            )\n            last += step\n#         lemmas.append(random.choice(corrupted))\n#         tokens.append(sub_tokens)\n         # уберем базовые предлоги и запятые\n        no_preps_lemmas = [lemma for lemma in random.choice(corrupted)\n                          if lemma not in [',', 'в', 'от', 'о', 'к', 'по', 'за', 'на']]\n        if no_preps_lemmas:\n            lemmas.append(no_preps_lemmas)\n            tokens.append(sub_tokens)\n        else: # если предложение состояло из мусора\n            continue\n    if lemmas:\n        return tokenizer(lemmas,\n                         text_target=tokens,\n                         **targs)\n    else: # может оказаться так что во всем батче не будут только длинные предложения\n        return {'input_ids':[],\n               'attention_mask':[],\n               'labels':[]}","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:33:17.028751Z","iopub.execute_input":"2024-05-15T09:33:17.029657Z","iopub.status.idle":"2024-05-15T09:33:17.040726Z","shell.execute_reply.started":"2024-05-15T09:33:17.029621Z","shell.execute_reply":"2024-05-15T09:33:17.039840Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_data = dataset.map(preprocess,\n                            batched=True,\n                            batch_size=8,\n                            remove_columns=dataset['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:25:28.977441Z","iopub.execute_input":"2024-05-15T09:25:28.977713Z","iopub.status.idle":"2024-05-15T09:25:56.493342Z","shell.execute_reply.started":"2024-05-15T09:25:28.977691Z","shell.execute_reply":"2024-05-15T09:25:56.492295Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/61461 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c469170adf604ce5bf55756d41a3af55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15366 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af468580123443c29fa9f8e5f53b46e9"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:25:56.494458Z","iopub.execute_input":"2024-05-15T09:25:56.494745Z","iopub.status.idle":"2024-05-15T09:25:56.501624Z","shell.execute_reply.started":"2024-05-15T09:25:56.494719Z","shell.execute_reply":"2024-05-15T09:25:56.500545Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 61037\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 15280\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# немножко увеличим наш датасет предложениями из совершенно другого корпуса\nfrom datasets import load_dataset\n\nadditional_dataset = load_dataset(\"universal_dependencies\", \"ru_syntagrus\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:26:08.008952Z","iopub.execute_input":"2024-05-15T09:26:08.009307Z","iopub.status.idle":"2024-05-15T09:26:14.588768Z","shell.execute_reply.started":"2024-05-15T09:26:08.009282Z","shell.execute_reply":"2024-05-15T09:26:14.587855Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading data: 100%|██████████| 19.0M/19.0M [00:01<00:00, 18.3MB/s]\nDownloading data: 100%|██████████| 2.58M/2.58M [00:00<00:00, 4.19MB/s]\nDownloading data: 100%|██████████| 2.56M/2.56M [00:01<00:00, 2.43MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/48814 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afd29c4a24ea469780566c85363a823d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/6584 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5efff576aa4b47beaac17a8b9870770b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/6491 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b8d176019a4536b3adf093bd3b6c4f"}},"metadata":{}}]},{"cell_type":"code","source":"add_data_tokens = additional_dataset.map(preprocess,\n                                        batched=True,\n                                        batch_size=8,\n                                        remove_columns=additional_dataset['train'].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:33:25.924154Z","iopub.execute_input":"2024-05-15T09:33:25.924995Z","iopub.status.idle":"2024-05-15T09:33:52.514866Z","shell.execute_reply.started":"2024-05-15T09:33:25.924951Z","shell.execute_reply":"2024-05-15T09:33:52.513906Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48814 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddde8c413c794ea485b17796bb457935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6584 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf0d26926b14d4985390ca00d02510f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6491 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6dc0ac6b0eb4a0b9628eb5376adffb8"}},"metadata":{}}]},{"cell_type":"code","source":"add_data_tokens","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:33:54.690328Z","iopub.execute_input":"2024-05-15T09:33:54.691141Z","iopub.status.idle":"2024-05-15T09:33:54.696949Z","shell.execute_reply.started":"2024-05-15T09:33:54.691108Z","shell.execute_reply":"2024-05-15T09:33:54.696010Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 37708\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 5096\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 5006\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import concatenate_datasets, DatasetDict\n\nvectors = concatenate_datasets([tokenized_data['train'],\n                                tokenized_data['test'],\n                                add_data_tokens['test'],\n                                add_data_tokens['validation'],\n                               ]).train_test_split(0.2)\nvectors","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:00.767906Z","iopub.execute_input":"2024-05-15T09:34:00.768277Z","iopub.status.idle":"2024-05-15T09:34:00.989179Z","shell.execute_reply.started":"2024-05-15T09:34:00.768247Z","shell.execute_reply":"2024-05-15T09:34:00.988247Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 69135\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 17284\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,\n                                       model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:05.537634Z","iopub.execute_input":"2024-05-15T09:34:05.538434Z","iopub.status.idle":"2024-05-15T09:34:15.897743Z","shell.execute_reply.started":"2024-05-15T09:34:05.538402Z","shell.execute_reply":"2024-05-15T09:34:15.896717Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2024-05-15 09:34:07.966539: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-15 09:34:07.966684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-15 09:34:08.108670: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nbleu = evaluate.load(\"sacrebleu\")\n# meteor = evaluate.load('meteor')\nchrf = evaluate.load(\"chrf\")","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:15.899485Z","iopub.execute_input":"2024-05-15T09:34:15.900123Z","iopub.status.idle":"2024-05-15T09:34:18.572846Z","shell.execute_reply.started":"2024-05-15T09:34:15.900094Z","shell.execute_reply":"2024-05-15T09:34:18.572067Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca00d06203c84d2e89ed0a87a56dbe97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b139f8973f1144bcb954015262520e7d"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n\n    return preds, labels\n\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n\n    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n#     meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n    chrf_result = chrf.compute(predictions=decoded_preds, references=decoded_labels)\n    result = {\"bleu\": bleu_result[\"score\"],\n#               \"meteor\": meteor_result['meteor'],\n              \"chrf\": chrf_result['score']}\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    result = {k: round(v, 4) for k, v in result.items()}\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:18.573994Z","iopub.execute_input":"2024-05-15T09:34:18.574522Z","iopub.status.idle":"2024-05-15T09:34:18.583703Z","shell.execute_reply.started":"2024-05-15T09:34:18.574495Z","shell.execute_reply":"2024-05-15T09:34:18.582833Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:18.585636Z","iopub.execute_input":"2024-05-15T09:34:18.585974Z","iopub.status.idle":"2024-05-15T09:34:27.601752Z","shell.execute_reply.started":"2024-05-15T09:34:18.585950Z","shell.execute_reply":"2024-05-15T09:34:27.600724Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1a3a5b5a354daba6925ee12c2ee4a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68a193bab0fe4dafab8b71da00040a85"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:28.662344Z","iopub.execute_input":"2024-05-15T09:34:28.662717Z","iopub.status.idle":"2024-05-15T09:34:28.701694Z","shell.execute_reply.started":"2024-05-15T09:34:28.662688Z","shell.execute_reply":"2024-05-15T09:34:28.700906Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d3b05745c6840f88c4ba049f0a1bba2"}},"metadata":{}}]},{"cell_type":"code","source":"from copy import deepcopy\nimport warnings\nwarnings.filterwarnings('ignore')\n\ngen_config = deepcopy(model.generation_config)\ngen_config.update(\n    max_length=MAX_LENGTH,\n)\ngen_config.validate()\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"t5-rebuilder-v2\",\n    overwrite_output_dir=True,\n    evaluation_strategy=\"epoch\",\n    num_train_epochs=3,\n    learning_rate=3e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    predict_with_generate=True,\n    generation_config=gen_config,\n    fp16=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=vectors['train'],\n    eval_dataset=vectors['test'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\n\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T09:34:48.454623Z","iopub.execute_input":"2024-05-15T09:34:48.455371Z","iopub.status.idle":"2024-05-15T10:46:36.577644Z","shell.execute_reply.started":"2024-05-15T09:34:48.455338Z","shell.execute_reply":"2024-05-15T10:46:36.576895Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240515_093511-3x2pba3w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/predlog/huggingface/runs/3x2pba3w' target=\"_blank\">fine-hill-10</a></strong> to <a href='https://wandb.ai/predlog/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/predlog/huggingface' target=\"_blank\">https://wandb.ai/predlog/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/predlog/huggingface/runs/3x2pba3w' target=\"_blank\">https://wandb.ai/predlog/huggingface/runs/3x2pba3w</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12963' max='12963' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12963/12963 1:11:07, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Chrf</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.446300</td>\n      <td>0.320490</td>\n      <td>78.661300</td>\n      <td>90.200400</td>\n      <td>13.296700</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.240000</td>\n      <td>0.237883</td>\n      <td>84.276300</td>\n      <td>92.789800</td>\n      <td>13.394000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.118000</td>\n      <td>0.220571</td>\n      <td>86.013400</td>\n      <td>93.657300</td>\n      <td>13.400700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=12963, training_loss=0.35032713222878864, metrics={'train_runtime': 4306.557, 'train_samples_per_second': 48.16, 'train_steps_per_second': 3.01, 'total_flos': 5563453560606720.0, 'train_loss': 0.35032713222878864, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T10:46:48.376583Z","iopub.execute_input":"2024-05-15T10:46:48.376992Z","iopub.status.idle":"2024-05-15T10:47:17.824127Z","shell.execute_reply.started":"2024-05-15T10:46:48.376958Z","shell.execute_reply":"2024-05-15T10:47:17.823045Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d93e573001634dc995db5123ce76af1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1715765690.19a19999c1eb.34.0:   0%|          | 0.00/14.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c45b249ebc4bc8a1a2a97e470a7345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fa91b56654242ef97a2403a1f902d5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/6.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095ed5189f8f4a95aa3d2fd321f0c1b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a42b50ddb84a40b59c9b53e4f68162b7"}},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/XvKuoMing/t5-rebuilder-v2/commit/37763dbeb90152dfcab5e7083b6520a7b8c826d8', commit_message='End of training', commit_description='', oid='37763dbeb90152dfcab5e7083b6520a7b8c826d8', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}